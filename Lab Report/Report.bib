Automatically generated by Mendeley Desktop 1.19.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Barto1983,
abstract = {It is shown how a system consisting of two neuronlike adaptive elements can solve a difficult learning control problem. The task is to balance a pole that is hinged to a movable cart by applying forces to the cart's base. It is assumed that the equations of motion of the cart-pole system are not known and that the only feedback evaluating performance is a failure signal that occurs when the pole falls past a certain angle from the vertical, or the cart reaches an end of a track. This evaluative feedback is of much lower quality than is required by standard adaptive control techniques. It is argued that the learning problems faced by adaptive elements that are components of adaptive networks are at least as difficult as this version of the pole-balancing problem. The learning system consists of a single associative search element (ASE) and a single adaptive critic element (ACE). In the course of learning to balance the pole, the ASE constructs associations between input and output by searching under the influence of reinforcement feedback, and the ACE constructs a more informative evaluation function than reinforcement feedback alone can provide. The differences between this approach and other attempts to solve problems using neuronlike elements are discussed, as is the relation of this work to classical and instrumental conditioning in animal learning studies and its possible implications for research in the neurosciences.},
annote = {cart pole, Neuron like element, equations, figures},
author = {Barto, Andrew G and Sutton, Richard S and Anderson, Charles W},
doi = {10.1109/TSMC.1983.6313077},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
month = {sep},
number = {5},
pages = {834--846},
title = {{Neuronlike adaptive elements that can solve difficult learning control problems}},
url = {http://ieeexplore.ieee.org/document/6313077/},
volume = {SMC-13},
year = {1983}
}
@book{Lund,
abstract = {This report presents a derivation of the Furuta pendulum dynamics using the Euler-Lagrange equations.},
author = {G{\"{a}}fvert, Magnus},
number = {April},
publisher = {Department of Automatic Control Lund Institute of Technology},
title = {{Modelling the Furuta pendulum}},
url = {http://www.control.lth.se/documents/1998/7574.pdf},
year = {1998}
}
@article{He2018,
abstract = {The NIR-laser-driven plasmonic photothermal and sustained drug release behavior of CuSâ€“PTX/SiO 2 nanocapsules show great synergistic chemo-photothermal therapeutic effects on cancer cells in vitro and in vivo .},
archivePrefix = {arXiv},
arxivId = {1506.02438v6},
author = {He, Jian and Ai, Lisha and Liu, Xin and Huang, Hao and Li, Yuebin and Zhang, Mingguang and Zhao, Qianru and Wang, Xingguo and Chen, Wei and Gu, Haoshuang},
doi = {10.1039/c7tb02772a},
eprint = {1506.02438v6},
file = {:home/janosch/Documents/Semester{\_}3/RL/Project/Saves/GAE paper.pdf:pdf},
isbn = {1506.02438v6},
issn = {2050750X},
journal = {Journal of Materials Chemistry B},
number = {7},
pages = {1035--1043},
pmid = {15949779},
title = {{Plasmonic CuS nanodisk assembly based composite nanocapsules for NIR-laser-driven synergistic chemo-photothermal cancer therapy}},
volume = {6},
year = {2018}
}
@inproceedings{Kakade2001,
author = {Kakade, Sham},
booktitle = {NIPS'01 Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic},
pages = {1531--1538},
title = {{A Natural Policy Gradient}},
year = {2001}
}
@inproceedings{Furuta1991,
address = {Kobe, Japan, Japan},
annote = {Furuta pendulum, equatons, derivation, figures,},
author = {Furuta, K and Yamakita, M and Kobayashi, S},
booktitle = {Proceedings IECON '91: 1991 International Conference on Industrial Electronics, Control and Instrumentation},
doi = {10.1109/IECON.1991.239008},
isbn = {0-87942-688-8},
pages = {2193--2198},
publisher = {IEEE},
title = {{Swing up control of inverted pendulum}},
url = {http://ieeexplore.ieee.org/document/239008/},
year = {1991}
}
@article{Rajeswaran2017,
abstract = {This work shows that policies with simple linear and RBF parameterizations can be trained to solve a variety of continuous control tasks, including the OpenAI gym benchmarks. The performance of these trained policies are competitive with state of the art results, obtained with more elaborate parameterizations such as fully connected neural networks. Furthermore, existing training and testing scenarios are shown to be very limited and prone to over-fitting, thus giving rise to only trajectory-centric policies. Training with a diverse initial state distribution is shown to produce more global policies with better generalization. This allows for interactive control scenarios where the system recovers from large on-line perturbations; as shown in the supplementary video.},
archivePrefix = {arXiv},
arxivId = {1703.02660},
author = {Rajeswaran, Aravind and Lowrey, Kendall and Todorov, Emanuel and Kakade, Sham},
doi = {10.1016/j.acra.2014.04.006},
eprint = {1703.02660},
isbn = {9781538632277},
issn = {18784046},
number = {Nips},
pmid = {25018067},
title = {{Towards Generalization and Simplicity in Continuous Control}},
url = {http://arxiv.org/abs/1703.02660},
year = {2017}
}
@article{SchulmanLMJA15,
archivePrefix = {arXiv},
arxivId = {1502.05477},
author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I and Abbeel, Pieter},
eprint = {1502.05477},
journal = {CoRR},
title = {{Trust Region Policy Optimization}},
url = {http://arxiv.org/abs/1502.05477},
volume = {abs/1502.0},
year = {2015}
}
@article{Wierstra14,
author = {Wierstra, Daan and Schaul, Tom and Glasmachers, Tobias and Sun, Yi and Peters, Jan and Schmidhuber, J{\"{u}}rgen},
journal = {Journal of Machine Learning Research},
pages = {949--980},
title = {{Natural Evolution Strategies}},
url = {http://jmlr.org/papers/v15/wierstra14a.html},
volume = {15},
year = {2014}
}
@article{Cazzolato2011,
abstract = {The Furuta pendulum, or rotational inverted pendulum, is a system found in many control labs. It provides a compact yet impressive platform for control demonstrations and draws the attention of the control community as a platform for the development of nonlinear control laws. Despite the popularity of the platform, there are very few papers which employ the correct dynamics and only one that derives the full system dynamics. In this paper, the full dynamics of the Furuta pendulum are derived using two methods: a Lagrangian formulation and an iterative Newton-Euler formulation. Approximations are made to the full dynamics which converge to the more commonly presented expressions. The system dynamics are then linearised using a Jacobian. To illustrate the influence the commonly neglected inertia terms have on the system dynamics, a brief example is offered.},
author = {Cazzolato, Benjamin Seth and Prime, Zebb},
doi = {10.1155/2011/528341},
file = {:home/janosch/Documents/Semester{\_}3/RL/Project/Seminar/Furuta Paper/On{\_}the{\_}Dynamics{\_}of{\_}the{\_}Furuta{\_}Pendulum.pdf:pdf},
issn = {1687-5249},
journal = {Journal of Control Science and Engineering},
number = {May},
pages = {1--8},
title = {{On the Dynamics of the Furuta Pendulum}},
volume = {2011},
year = {2011}
}
@misc{Telesens,
author = {{Ankur Mohan}},
title = {{Efficiently Computing the Fisher Vector Product in TRPO}},
url = {http://www.telesens.co/2018/06/09/efficiently-computing-the-fisher-vector-product-in-trpo/},
urldate = {2019-03-12},
year = {2018}
}
@article{DuanCHSA16,
archivePrefix = {arXiv},
arxivId = {1604.06778},
author = {Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
eprint = {1604.06778},
journal = {CoRR},
title = {{Benchmarking Deep Reinforcement Learning for Continuous Control}},
url = {http://arxiv.org/abs/1604.06778},
volume = {abs/1604.0},
year = {2016}
}
